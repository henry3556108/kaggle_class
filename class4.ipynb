{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c35b805",
   "metadata": {},
   "source": [
    "## 回歸樹（Regression Trees）\n",
    "回歸樹（Regression Trees）是決策樹（Decision Trees）的一種形式，專門用於解決回歸問題，即當目標變量是連續值而不是離散類別時。回歸樹通過從數據中學習決策規則來預測一個連續的數值。這與分類樹類似，但分類樹的目的是預測數據的類別標籤。\n",
    "\n",
    "### 基本原理\n",
    "    - 回歸樹的工作原理與決策樹相似，但在決定每個節點如何分割數據時，它考慮的是減少預測誤差而不是增加信息增益或純度。具體來說，回歸樹通過以下步驟建模：\n",
    "    1. 選擇最佳分割：選擇一個特徵和一個閾值將數據分成兩個子集，使得這個分割最大程度減少目標變量的總平方誤差（SSE）。\n",
    "    2. 遞歸分割：對每個子集重複這個分割過程，直到達到一個停止條件（如最大深度、最小樣本數等）。\n",
    "    3. 預測輸出：在每個葉節點（終端節點），輸出的預測值是該節點所有樣本目標值的平均值。\n",
    "    \n",
    "### 模型評估與過擬合\n",
    "與所有機器學習模型一樣，回歸樹也容易發生過擬合，尤其是當樹太深或樹中的節點包含太少的樣本時。為了避免過擬合，通常會使用一些策略，如：\n",
    "1. 剪枝：減少樹的大小，通過去除對最終模型預測能力貢獻不大的節點。\n",
    "2. 設定最大深度：限制樹的深度。\n",
    "3. 最小樣本分割：設定節點分割前必須擁有的最小樣本數。\n",
    "\n",
    "- [延伸閱讀](https://zhuanlan.zhihu.com/p/82054400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481907f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入所需的庫\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 加載數據集\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# 劃分訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 創建回歸樹模型\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# 進行預測\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# 評估模型\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"均方根誤差（RMSE）:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6609ca2",
   "metadata": {},
   "source": [
    "## sklearn.PolynomialFeatures \n",
    "- sklearn.PolynomialFeatures 是一個在 Python 的 scikit-learn 库中用來生成多項式特徵的工具，這些特徵是現有特徵的高階和交互項。這種轉換常常用於多項式回歸，其中這些多項式特徵能夠提供非線性的擬合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf195ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly regression model\n",
      "R2 on Test Set: 0.6533650021677881\n",
      "Training Score: 0.6838081517893657\n",
      "Testing Score: 0.6533650021677881\n",
      "\n",
      "Regular regression model\n",
      "R2 on Test Set: 0.5957702326061661\n",
      "Training Score: 0.6093459727972159\n",
      "Testing Score: 0.5957702326061661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 載入數據集\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# 創建多項式特徵生成器，degree=2\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# 分割數據集\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_poly, y, test_size=0.3, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 創建並訓練線性回歸模型\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train1, y_train1)\n",
    "\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "# 進行預測並評估模型\n",
    "y_pred1 = model1.predict(X_test1)\n",
    "r2_1 = r2_score(y_test1, y_pred1)\n",
    "\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "r2_2 = r2_score(y_test2, y_pred2)\n",
    "\n",
    "print(\"Poly regression model\")\n",
    "print(\"R2 on Test Set:\", r2_1)\n",
    "print(\"Training Score:\", model1.score(X_train1, y_train1))\n",
    "print(\"Testing Score:\", model1.score(X_test1, y_test1))\n",
    "\n",
    "print() # 只是為了排版，所以使用它會多一行空白 print(end=\"\\n\") 預設會換行\n",
    "\n",
    "print(\"Regular regression model\")\n",
    "print(\"R2 on Test Set:\", r2_2)\n",
    "print(\"Training Score:\", model2.score(X_train2, y_train2))\n",
    "print(\"Testing Score:\", model2.score(X_test2, y_test2))\n",
    "\n",
    "# score 是 R2 score 怎麼樣才是比較好的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用以上的 code 思考一下要怎麼改成使用 DecisionTreeRegressor 來"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44ea5d",
   "metadata": {},
   "source": [
    "- [延伸閱讀](https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4659d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
